{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rKvFrWOSs85d"
   },
   "source": [
    "# NLP - Scalable, Accurate, Rule-Based pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# üß© Mercury App Configuration\n",
    "# ============================================================\n",
    "import mercury as mr\n",
    "\n",
    "app = mr.App(\n",
    "    title=\"NLP Text Classification Dashboard\",\n",
    "    description=\"Upload CSV or Excel files to classify transcripts using NLP.\"\n",
    ")\n",
    "\n",
    "file = mr.File(label=\"üìÅ Upload Dataset (.csv or .xlsx)\")\n",
    "run_button = mr.Button(label=\"üöÄ Run NLP Pipeline\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# üì¶ Imports & Configuration\n",
    "# ============================================================\n",
    "import os, re, time, warnings\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "from afinn import Afinn\n",
    "from langdetect import detect, DetectorFactory\n",
    "import spacy\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "DetectorFactory.seed = 0\n",
    "af = Afinn()\n",
    "\n",
    "# Load spacy model with error handling\n",
    "try:\n",
    "    nlp = spacy.load(\"en_core_web_sm\", disable=[\"ner\", \"parser\", \"tagger\"])\n",
    "except OSError:\n",
    "    print(\"‚ö†Ô∏è spaCy model 'en_core_web_sm' not found.\")\n",
    "    print(\"Please run: python -m spacy download en_core_web_sm\")\n",
    "    nlp = None\n",
    "\n",
    "NUM_THREADS = 8  # Adjust based on CPU cores\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# üìö Category and Subcategory Keywords\n",
    "# ============================================================\n",
    "TOPIC_KEYWORDS = {\n",
    "    \"login issue\": [\"login\", \"log in\", \"sign in\", \"sign-in\", \"sign out\", \"sign-out\",\n",
    "                    \"password\", \"forgot password\", \"reset password\", \"authentication\",\n",
    "                    \"verify account\", \"verification code\", \"2fa\", \"two-factor\",\n",
    "                    \"unable to access account\"],\n",
    "    \"account issue\": [\"account\", \"profile\", \"username\", \"display name\",\n",
    "                      \"linked account\", \"merge account\", \"multiple accounts\",\n",
    "                      \"email change\", \"update details\", \"account disabled\",\n",
    "                      \"account locked\", \"deactivate account\"],\n",
    "    \"playback issue\": [\"playback\", \"stream\", \"music not playing\", \"song not playing\",\n",
    "                       \"track skipped\", \"buffering\", \"lag\", \"pause\", \"stuck\",\n",
    "                       \"stops suddenly\", \"won't play\", \"audio issue\", \"no sound\",\n",
    "                       \"silence\", \"volume problem\"],\n",
    "    \"device issue\": [\"bluetooth\", \"speaker\", \"carplay\", \"android auto\", \"smart tv\",\n",
    "                     \"echo\", \"alexa\", \"chromecast\", \"airplay\", \"headphones\",\n",
    "                     \"device not showing\", \"device disconnected\"],\n",
    "    \"content restriction\": [\"song not available\", \"track unavailable\", \"region restriction\",\n",
    "                            \"country restriction\", \"not licensed\", \"greyed out\", \"removed song\"],\n",
    "    \"ad issue\": [\"ads\", \"advertisement\", \"too many ads\", \"ad volume\",\n",
    "                 \"ad playing\", \"premium ads\", \"commercials\"],\n",
    "    \"recommendation issue\": [\"recommendations\", \"discover weekly\", \"radio\", \"algorithm\",\n",
    "                             \"curated\", \"autoplay\", \"song suggestions\", \"not relevant\"],\n",
    "    \"ui issue\": [\"interface\", \"layout\", \"design\", \"dark mode\",\n",
    "                 \"buttons not working\", \"search not working\", \"filter not working\"],\n",
    "    \"general feedback\": [\"suggestion\", \"feedback\", \"recommend\", \"love spotify\",\n",
    "                         \"like app\", \"app improvement\", \"feature request\"],\n",
    "    \"network failure\": [\"network\", \"connectivity\", \"internet\", \"server\",\n",
    "                        \"connection failed\", \"offline\", \"not connecting\",\n",
    "                        \"spotify down\", \"timeout\", \"dns\", \"proxy\", \"vpn\"],\n",
    "    \"app crash\": [\"crash\", \"crashed\", \"app closed\", \"stopped working\", \"freeze\",\n",
    "                  \"freezing\", \"hang\", \"lag\", \"bug\", \"error message\", \"glitch\",\n",
    "                  \"slow performance\", \"unresponsive\"],\n",
    "    \"performance issue\": [\"slow\", \"lag\", \"delay\", \"performance\"],\n",
    "    \"data sync issue\": [\"sync\", \"not syncing\", \"listening history\", \"recently played\",\n",
    "                        \"activity feed\", \"spotify connect\", \"data lost\", \"missing data\"],\n",
    "    \"subscription issue\": [\"subscription\", \"plan\", \"premium\", \"cancel\", \"renew\",\n",
    "                           \"billing\", \"charged\", \"payment\", \"refund\", \"invoice\",\n",
    "                           \"upgrade\", \"downgrade\", \"free trial\", \"family plan\",\n",
    "                           \"student plan\", \"gift card\", \"promo code\", \"spotify wrapped\",\n",
    "                           \"card\"],\n",
    "}\n",
    "\n",
    "SUBCATEGORY_KEYWORDS = {\n",
    "    \"subscription issue\": {\n",
    "        \"payment\": [\"refund\", \"charged\", \"billing\", \"invoice\", \"payment\"],\n",
    "        \"cancel\": [\"cancel\", \"unsubscribe\", \"stop subscription\"],\n",
    "        \"upgrade\": [\"upgrade\", \"family plan\", \"student plan\", \"premium\"],\n",
    "    },\n",
    "    \"account issue\": {\n",
    "        \"login\": [\"login\", \"password\", \"signin\"],\n",
    "        \"profile\": [\"profile\", \"email\", \"username\", \"display name\"],\n",
    "    },\n",
    "    \"device issue\": {\n",
    "        \"mobile\": [\"phone\", \"android\", \"iphone\"],\n",
    "        \"car\": [\"carplay\", \"android auto\"],\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# ‚öñÔ∏è Rules and Helper Functions\n",
    "# ============================================================\n",
    "RULE_OVERRIDES = [\n",
    "    (lambda txt: any(k in txt.lower() for k in [\"refund\", \"charged\", \"billing\"]),\n",
    "     lambda preds: {**preds, \"category\": \"subscription issue\", \"subcategory\": \"payment\", \"sentiment\": \"negative\"}),\n",
    "    (lambda txt: \"cancel\" in txt.lower(),\n",
    "     lambda preds: {**preds, \"category\": \"subscription issue\", \"subcategory\": \"cancel\"}),\n",
    "]\n",
    "\n",
    "def is_english(text):\n",
    "    try:\n",
    "        return detect(text) == \"en\"\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "def extract_consumer_text(transcript):\n",
    "    if not isinstance(transcript, str):\n",
    "        return \"\"\n",
    "    parts = re.findall(r\"(?i)Consumer:\\s*(.*?)(?=\\s*\\|\\s*\\d{4}-\\d{2}-\\d{2}|$|\\s*\\|\\s*Agent:)\", transcript + \" \")\n",
    "    if not parts:\n",
    "        parts = re.findall(r\"(?i)Consumer:\\s*(.*?)(?=\\||$)\", transcript + \"|\")\n",
    "    return \" \".join(p.strip() for p in parts if p.strip())\n",
    "\n",
    "def hybrid_sentiment(text):\n",
    "    if not text or not is_english(text):\n",
    "        return \"\"\n",
    "    tb_score = TextBlob(text).sentiment.polarity\n",
    "    af_score = af.score(text) / 5.0\n",
    "    score = 0.6 * tb_score + 0.4 * af_score\n",
    "    if score <= -0.75: return \"very negative\"\n",
    "    elif score <= -0.25: return \"negative\"\n",
    "    elif score >= 0.75: return \"very positive\"\n",
    "    elif score >= 0.25: return \"positive\"\n",
    "    else: return \"neutral\"\n",
    "\n",
    "def predict_category(text):\n",
    "    text_lower = text.lower()\n",
    "    best_match, best_score = \"\", 0\n",
    "    for category, keywords in TOPIC_KEYWORDS.items():\n",
    "        matches = sum(k in text_lower for k in keywords)\n",
    "        if matches > best_score:\n",
    "            best_score = matches\n",
    "            best_match = category\n",
    "    return best_match\n",
    "\n",
    "def predict_subcategory(category, text):\n",
    "    if not category or category not in SUBCATEGORY_KEYWORDS:\n",
    "        return \"\"\n",
    "    text_lower = text.lower()\n",
    "    for sub, keywords in SUBCATEGORY_KEYWORDS[category].items():\n",
    "        if any(k in text_lower for k in keywords):\n",
    "            return sub\n",
    "    return \"\"\n",
    "\n",
    "def apply_rules(text, preds):\n",
    "    for cond, override in RULE_OVERRIDES:\n",
    "        if cond(text):\n",
    "            preds = override(preds)\n",
    "    return preds\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# üîÑ Core Row Processing\n",
    "# ============================================================\n",
    "def process_row(row):\n",
    "    conversation_id = row.get(\"Conversation Id\", \"\")\n",
    "    transcript = str(row.get(\"transcripts\", \"\"))\n",
    "    consumer_text = extract_consumer_text(transcript)\n",
    "    \n",
    "    if not consumer_text.strip() or not is_english(consumer_text):\n",
    "        return {\n",
    "            \"Conversation Id\": conversation_id,\n",
    "            \"Consumer_Text\": consumer_text,\n",
    "            \"Category\": \"\",\n",
    "            \"Subcategory\": \"\",\n",
    "            \"Sentiment\": \"\",\n",
    "        }\n",
    "    \n",
    "    preds = {\n",
    "        \"category\": predict_category(consumer_text),\n",
    "        \"subcategory\": \"\",\n",
    "        \"sentiment\": hybrid_sentiment(consumer_text),\n",
    "    }\n",
    "    preds[\"subcategory\"] = predict_subcategory(preds[\"category\"], consumer_text)\n",
    "    preds = apply_rules(consumer_text, preds)\n",
    "    \n",
    "    return {\n",
    "        \"Conversation Id\": conversation_id,\n",
    "        \"Consumer_Text\": consumer_text,\n",
    "        \"Category\": preds[\"category\"],\n",
    "        \"Subcategory\": preds[\"subcategory\"],\n",
    "        \"Sentiment\": preds[\"sentiment\"],\n",
    "    }\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# üßÆ Run NLP Pipeline with Mercury Integration\n",
    "# ============================================================\n",
    "def run_pipeline(uploaded_file):\n",
    "    start = time.time()\n",
    "    \n",
    "    # Mercury 4.x: use .filepath instead of .path\n",
    "    file_path = uploaded_file.filepath\n",
    "    \n",
    "    # Get original filename for extension check\n",
    "    original_name = getattr(uploaded_file, 'filename', '') or getattr(uploaded_file, 'name', '')\n",
    "    \n",
    "    # Load dataset - try both formats\n",
    "    df = None\n",
    "    error_msg = \"\"\n",
    "    \n",
    "    # First, try based on original filename\n",
    "    if original_name.lower().endswith('.xlsx'):\n",
    "        try:\n",
    "            df = pd.read_excel(file_path)\n",
    "        except Exception as e:\n",
    "            error_msg = f\"Excel read error: {str(e)}\"\n",
    "    elif original_name.lower().endswith('.csv'):\n",
    "        try:\n",
    "            df = pd.read_csv(file_path)\n",
    "        except Exception as e:\n",
    "            error_msg = f\"CSV read error: {str(e)}\"\n",
    "    \n",
    "    # If original name didn't work, try auto-detection\n",
    "    if df is None:\n",
    "        try:\n",
    "            # Try Excel first\n",
    "            df = pd.read_excel(file_path)\n",
    "        except:\n",
    "            try:\n",
    "                # Try CSV\n",
    "                df = pd.read_csv(file_path)\n",
    "            except Exception as e:\n",
    "                raise ValueError(f\"Could not read file. {error_msg}. Last attempt: {str(e)}\")\n",
    "    \n",
    "    if df is None:\n",
    "        raise ValueError(\"Unsupported file format. Upload a .csv or .xlsx file.\")\n",
    "    \n",
    "    # Validate required columns\n",
    "    if \"Conversation Id\" not in df.columns or \"transcripts\" not in df.columns:\n",
    "        raise ValueError(\"Input file must contain 'Conversation Id' and 'transcripts' columns.\")\n",
    "    \n",
    "    # Parallel processing\n",
    "    with ThreadPoolExecutor(max_workers=NUM_THREADS) as executor:\n",
    "        results = list(executor.map(process_row, df.to_dict(\"records\")))\n",
    "    \n",
    "    # Create output dataframe\n",
    "    out_df = pd.DataFrame(results)\n",
    "    out_df.to_csv(\"sentiment_output.csv\", index=False)\n",
    "    \n",
    "    elapsed = time.time() - start\n",
    "    print(f\"‚úÖ Completed in {elapsed:.2f}s. Processed {len(out_df)} rows.\")\n",
    "    \n",
    "    return out_df\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# üñ•Ô∏è Execute & Display Results\n",
    "# ============================================================\n",
    "if run_button.clicked:\n",
    "    if file is None or not hasattr(file, 'filepath') or file.filepath is None:\n",
    "        mr.Markdown(\"### ‚ö†Ô∏è Please upload a .csv or .xlsx file before running the pipeline.\")\n",
    "    elif nlp is None:\n",
    "        mr.Markdown(\"### ‚ùå Error: spaCy model not installed\")\n",
    "        mr.Markdown(\"Please run in your terminal: `python -m spacy download en_core_web_sm`\")\n",
    "    else:\n",
    "        try:\n",
    "            mr.Markdown(\"### üîÑ Processing...\")\n",
    "            df_result = run_pipeline(file)\n",
    "            \n",
    "            mr.Markdown(\"### ‚úÖ Processing Complete!\")\n",
    "            mr.Markdown(f\"**Total rows processed:** {len(df_result)}\")\n",
    "            \n",
    "            # Display results - just show the dataframe directly\n",
    "            mr.Markdown(\"### üìä Results Preview (First 100 rows)\")\n",
    "            df_result.head(100)  # Jupyter will display this automatically\n",
    "            \n",
    "            # Download button\n",
    "            mr.Markdown(\"### üì• Download Results\")\n",
    "            mr.Markdown(\"[Download sentiment_output.csv](sentiment_output.csv)\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            mr.Markdown(f\"### ‚ùå Error processing file\")\n",
    "            mr.Markdown(f\"**Error details:** {str(e)}\")\n",
    "else:\n",
    "    mr.Markdown(\"### üëã Welcome to NLP Text Classification Dashboard\")\n",
    "    mr.Markdown(\"1. Upload your CSV or Excel file containing 'Conversation Id' and 'transcripts' columns\")\n",
    "    mr.Markdown(\"2. Click the 'Run NLP Pipeline' button to start processing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "NLP Mercury Env",
   "language": "python",
   "name": "nlp_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
